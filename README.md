# Implementation-of-the-Line-Search-Algorithm

This project focuses on implementing optimization algorithms, specifically the Line Search and BFGS methods, to solve complex mathematical functions. The algorithms are designed to demonstrate principles in 
optimization theory and improve convergence rates in various scenarios.

## Part1
In this section, we intend to implement the line search algorithm along with the zoom algorithm. The line search algorithm with zoom is an iterative method used to find an appropriate step size (also known as step
length or learning rate) along a given search direction in optimization problems. It is commonly used in optimization algorithms such as gradient descent methods or conjugate gradient methods.

## Part2
In this section, we will use the BFGS algorithm for optimization. BFGS is a popular quasi-Newton method for unconstrained optimization. It is known for its efficiency in practice and often requires fewer function evaluations compared to other optimization methods. The BFGS algorithm approximates the Hessian matrix using updates from gradient information. Due to its simplicity, efficiency, and good convergence properties, it is widely used for many optimization problems. However, if the objective function has characteristics such as high dimensions, non-convexity, or unfavorable properties, its performance may decline.
We will examine the convergence behavior and the number of function evaluations to assess the performance of BFGS for our specific optimization problem.
